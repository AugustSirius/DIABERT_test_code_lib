{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:WARNING: No Bruker libraries are available for this operating system. Mobility and m/z values need to be estimated. While this estimation often returns acceptable results with errors < 0.02 Th, huge errors (e.g. offsets of 6 Th) have already been observed for some samples!\n",
      "/Users/augustsirius/Desktop/DIABERT_test_code_lib/timstof_to_df/timstof_PASEF_20250506.py:237: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  frames.Id[0] = 0\n",
      "/Users/augustsirius/Desktop/DIABERT_test_code_lib/timstof_to_df/timstof_PASEF_20250506.py:238: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  frames.Time[0] = 0\n",
      "/Users/augustsirius/Desktop/DIABERT_test_code_lib/timstof_to_df/timstof_PASEF_20250506.py:239: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  frames.MaxIntensity[0] = 0\n",
      "/Users/augustsirius/Desktop/DIABERT_test_code_lib/timstof_to_df/timstof_PASEF_20250506.py:240: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  frames.SummedIntensities[0] = 0\n",
      "/Users/augustsirius/Desktop/DIABERT_test_code_lib/timstof_to_df/timstof_PASEF_20250506.py:241: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  frames.NumPeaks[0] = 0\n",
      "/Users/augustsirius/Desktop/DIABERT_test_code_lib/timstof_to_df/timstof_PASEF_20250506.py:242: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  frames.MsMsType[0] = 0\n",
      "100%|██████████| 14131/14131 [00:01<00:00, 8964.57it/s] \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 从 Untitled_im_rt_test.ipynb 转换而来\n",
    "\n",
    "# ==================== Cell 1 ====================\n",
    "import os\n",
    "import torch\n",
    "import timstof_PASEF_20250506\n",
    "from copy import deepcopy\n",
    "# import model_handler\n",
    "# from score_model import DIArtModel\n",
    "import torch.nn as nn\n",
    "# from score_model import FeatureEngineer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "  \n",
    "bruker_d_folder_name = '/Users/augustsirius/Desktop/DIABERT_test_code_lib/timstof_to_df/DIA_sample.d'\n",
    "timstof_data = timstof_PASEF_20250506.TimsTOF(bruker_d_folder_name)\n",
    "df = deepcopy(timstof_data[:,:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "详细分析 TimsTOF 质谱数据\n",
      "================================================================================\n",
      "\n",
      "1. 基本信息:\n",
      "   数据类型: <class 'pandas.core.frame.DataFrame'>\n",
      "   形状 (行数, 列数): (44820114, 14)\n",
      "   总元素数量: 627481596\n",
      "   维度: 2\n",
      "\n",
      "2. 列信息:\n",
      "   列数量: 14\n",
      "   列名称: ['raw_indices', 'frame_indices', 'scan_indices', 'precursor_indices', 'push_indices', 'tof_indices', 'rt_values', 'rt_values_min', 'mobility_values', 'quad_low_mz_values', 'quad_high_mz_values', 'mz_values', 'intensity_values', 'corrected_intensity_values']\n",
      "\n",
      "3. 索引信息:\n",
      "   索引类型: <class 'pandas.core.indexes.range.RangeIndex'>\n",
      "   索引范围: 0 到 44820113\n",
      "   索引名称: None\n",
      "\n",
      "4. 数据类型详情:\n",
      "   float64: 6 列\n",
      "   int64: 5 列\n",
      "   uint32: 2 列\n",
      "   uint16: 1 列\n",
      "\n",
      "   各列数据类型:\n",
      "   raw_indices: int64\n",
      "   frame_indices: int64\n",
      "   scan_indices: int64\n",
      "   precursor_indices: int64\n",
      "   push_indices: int64\n",
      "   tof_indices: uint32\n",
      "   rt_values: float64\n",
      "   rt_values_min: float64\n",
      "   mobility_values: float64\n",
      "   quad_low_mz_values: float64\n",
      "   quad_high_mz_values: float64\n",
      "   mz_values: float64\n",
      "   intensity_values: uint16\n",
      "   corrected_intensity_values: uint32\n",
      "\n",
      "5. 缺失值分析:\n",
      "   总缺失值: 0\n",
      "   缺失值比例: 0.00%\n",
      "\n",
      "6. 内存使用情况:\n",
      "   总内存使用: 4188.89 MB\n",
      "   各列内存使用:\n",
      "   raw_indices: 341.95 MB\n",
      "   frame_indices: 341.95 MB\n",
      "   scan_indices: 341.95 MB\n",
      "   precursor_indices: 341.95 MB\n",
      "   push_indices: 341.95 MB\n",
      "   tof_indices: 170.98 MB\n",
      "   rt_values: 341.95 MB\n",
      "   rt_values_min: 341.95 MB\n",
      "   mobility_values: 341.95 MB\n",
      "   quad_low_mz_values: 341.95 MB\n",
      "   quad_high_mz_values: 341.95 MB\n",
      "   mz_values: 341.95 MB\n",
      "   intensity_values: 85.49 MB\n",
      "   corrected_intensity_values: 170.98 MB\n",
      "\n",
      "7. 数值列统计信息:\n",
      "   数值列数量: 14\n",
      "\n",
      "   raw_indices:\n",
      "     最小值: 0\n",
      "     最大值: 44820113\n",
      "     平均值: 22410056.500000\n",
      "     中位数: 22410056.500000\n",
      "     标准差: 12938452.585843\n",
      "     非零值数量: 44820113\n",
      "     唯一值数量: 44820114\n",
      "\n",
      "   frame_indices:\n",
      "     最小值: 1\n",
      "     最大值: 14131\n",
      "     平均值: 7591.089998\n",
      "     中位数: 7687.000000\n",
      "     标准差: 3636.446381\n",
      "     非零值数量: 44820114\n",
      "     唯一值数量: 14131\n",
      "\n",
      "   scan_indices:\n",
      "     最小值: 33\n",
      "     最大值: 926\n",
      "     平均值: 372.224527\n",
      "     中位数: 356.000000\n",
      "     标准差: 198.025540\n",
      "     非零值数量: 44820114\n",
      "     唯一值数量: 894\n",
      "\n",
      "   precursor_indices:\n",
      "     最小值: 0\n",
      "     最大值: 8\n",
      "     平均值: 0.761655\n",
      "     中位数: 0.000000\n",
      "     标准差: 1.896302\n",
      "     非零值数量: 7810562\n",
      "     唯一值数量: 9\n",
      "\n",
      "   push_indices:\n",
      "     最小值: 961\n",
      "     最大值: 13114494\n",
      "     平均值: 7044903.742306\n",
      "     中位数: 7134042.000000\n",
      "     标准差: 3374618.693599\n",
      "     非零值数量: 44820114\n",
      "     唯一值数量: 7251524\n",
      "\n",
      "   tof_indices:\n",
      "     最小值: 0\n",
      "     最大值: 394427\n",
      "     平均值: 188552.220339\n",
      "     中位数: 183298.000000\n",
      "     标准差: 62618.523135\n",
      "     非零值数量: 44820091\n",
      "     唯一值数量: 384540\n",
      "\n",
      "   rt_values:\n",
      "     最小值: 0.702978\n",
      "     最大值: 1499.938421\n",
      "     平均值: 805.629586\n",
      "     中位数: 815.675520\n",
      "     标准差: 385.777499\n",
      "     非零值数量: 44820114\n",
      "     唯一值数量: 14131\n",
      "\n",
      "   rt_values_min:\n",
      "     最小值: 0.0117163\n",
      "     最大值: 24.998973683333336\n",
      "     平均值: 13.427160\n",
      "     中位数: 13.594592\n",
      "     标准差: 6.429625\n",
      "     非零值数量: 44820114\n",
      "     唯一值数量: 14131\n",
      "\n",
      "   mobility_values:\n",
      "     最小值: 0.6512931034482758\n",
      "     最大值: 1.2286637931034483\n",
      "     平均值: 1.009338\n",
      "     中位数: 1.019828\n",
      "     标准差: 0.128034\n",
      "     非零值数量: 44820114\n",
      "     唯一值数量: 894\n",
      "\n",
      "   quad_low_mz_values:\n",
      "     最小值: -1.0\n",
      "     最大值: 900.0\n",
      "     平均值: 114.845026\n",
      "     中位数: -1.000000\n",
      "     标准差: 259.372964\n",
      "     非零值数量: 44820114\n",
      "     唯一值数量: 23\n",
      "\n",
      "   quad_high_mz_values:\n",
      "     最小值: -1.0\n",
      "     最大值: 925.0\n",
      "     平均值: 119.201643\n",
      "     中位数: -1.000000\n",
      "     标准差: 268.602190\n",
      "     非零值数量: 44820114\n",
      "     唯一值数量: 23\n",
      "\n",
      "   mz_values:\n",
      "     最小值: 100.00054899999999\n",
      "     最大值: 1699.986941266157\n",
      "     平均值: 646.071241\n",
      "     中位数: 600.917978\n",
      "     标准差: 264.569958\n",
      "     非零值数量: 44820114\n",
      "     唯一值数量: 384540\n",
      "\n",
      "   intensity_values:\n",
      "     最小值: 9\n",
      "     最大值: 36884\n",
      "     平均值: 71.638616\n",
      "     中位数: 70.000000\n",
      "     标准差: 79.767086\n",
      "     非零值数量: 44820114\n",
      "     唯一值数量: 2800\n",
      "\n",
      "   corrected_intensity_values:\n",
      "     最小值: 9\n",
      "     最大值: 36884\n",
      "     平均值: 71.638616\n",
      "     中位数: 70.000000\n",
      "     标准差: 79.767086\n",
      "     非零值数量: 44820114\n",
      "     唯一值数量: 2800\n",
      "\n",
      "8. 非数值列信息:\n",
      "   没有非数值列\n",
      "\n",
      "9. 数据预览:\n",
      "   前5行:\n",
      "   raw_indices  frame_indices  scan_indices  precursor_indices  push_indices  tof_indices  rt_values  rt_values_min  mobility_values  quad_low_mz_values  quad_high_mz_values   mz_values  intensity_values  corrected_intensity_values\n",
      "0            0              1            33                  0           961        11401   0.702978       0.011716         1.228664                -1.0                 -1.0  118.870234               117                         117\n",
      "1            1              1            33                  0           961       193183   0.702978       0.011716         1.228664                -1.0                 -1.0  639.904122                93                          93\n",
      "2            2              1            33                  0           961       231777   0.702978       0.011716         1.228664                -1.0                 -1.0  803.847978                85                          85\n",
      "3            3              1            33                  0           961       254438   0.702978       0.011716         1.228664                -1.0                 -1.0  908.812607                39                          39\n",
      "4            4              1            33                  0           961       268236   0.702978       0.011716         1.228664                -1.0                 -1.0  975.878216                84                          84\n",
      "\n",
      "   后5行:\n",
      "          raw_indices  frame_indices  scan_indices  precursor_indices  push_indices  tof_indices    rt_values  rt_values_min  mobility_values  quad_low_mz_values  quad_high_mz_values   mz_values  intensity_values  corrected_intensity_values\n",
      "44820109     44820109          14131           924                  0      13114492       109356  1499.938421      24.998974         0.652586                -1.0                 -1.0  348.153598                86                          86\n",
      "44820110     44820110          14131           926                  0      13114494        52364  1499.938421      24.998974         0.651293                -1.0                 -1.0  200.115756               143                         143\n",
      "44820111     44820111          14131           926                  0      13114494        92482  1499.938421      24.998974         0.651293                -1.0                 -1.0  300.078886               105                         105\n",
      "44820112     44820112          14131           926                  0      13114494       109651  1499.938421      24.998974         0.651293                -1.0                 -1.0  349.025819                68                          68\n",
      "44820113     44820113          14131           926                  0      13114494       127308  1499.938421      24.998974         0.651293                -1.0                 -1.0  403.219262                63                          63\n",
      "\n",
      "10. DataFrame.info() 详情:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44820114 entries, 0 to 44820113\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Dtype  \n",
      "---  ------                      -----  \n",
      " 0   raw_indices                 int64  \n",
      " 1   frame_indices               int64  \n",
      " 2   scan_indices                int64  \n",
      " 3   precursor_indices           int64  \n",
      " 4   push_indices                int64  \n",
      " 5   tof_indices                 uint32 \n",
      " 6   rt_values                   float64\n",
      " 7   rt_values_min               float64\n",
      " 8   mobility_values             float64\n",
      " 9   quad_low_mz_values          float64\n",
      " 10  quad_high_mz_values         float64\n",
      " 11  mz_values                   float64\n",
      " 12  intensity_values            uint16 \n",
      " 13  corrected_intensity_values  uint32 \n",
      "dtypes: float64(6), int64(5), uint16(1), uint32(2)\n",
      "memory usage: 4.1 GB\n",
      "\n",
      "11. 描述性统计:\n",
      "        raw_indices  frame_indices  scan_indices  precursor_indices  push_indices   tof_indices     rt_values  rt_values_min  mobility_values  quad_low_mz_values  quad_high_mz_values     mz_values  intensity_values  corrected_intensity_values\n",
      "count  4.482011e+07   4.482011e+07  4.482011e+07       4.482011e+07  4.482011e+07  4.482011e+07  4.482011e+07   4.482011e+07     4.482011e+07        4.482011e+07         4.482011e+07  4.482011e+07      4.482011e+07                4.482011e+07\n",
      "mean   2.241006e+07   7.591090e+03  3.722245e+02       7.616552e-01  7.044904e+06  1.885522e+05  8.056296e+02   1.342716e+01     1.009338e+00        1.148450e+02         1.192016e+02  6.460712e+02      7.163862e+01                7.163862e+01\n",
      "std    1.293845e+07   3.636446e+03  1.980255e+02       1.896302e+00  3.374619e+06  6.261852e+04  3.857775e+02   6.429625e+00     1.280338e-01        2.593730e+02         2.686022e+02  2.645700e+02      7.976709e+01                7.976709e+01\n",
      "min    0.000000e+00   1.000000e+00  3.300000e+01       0.000000e+00  9.610000e+02  0.000000e+00  7.029780e-01   1.171630e-02     6.512931e-01       -1.000000e+00        -1.000000e+00  1.000005e+02      9.000000e+00                9.000000e+00\n",
      "25%    1.120503e+07   4.776000e+03  2.060000e+02       0.000000e+00  4.432780e+06  1.477350e+05  5.070192e+02   8.450320e+00     9.131466e-01       -1.000000e+00        -1.000000e+00  4.707918e+02      4.900000e+01                4.900000e+01\n",
      "50%    2.241006e+07   7.687000e+03  3.560000e+02       0.000000e+00  7.134042e+06  1.832980e+05  8.156755e+02   1.359459e+01     1.019828e+00       -1.000000e+00        -1.000000e+00  6.009180e+02      7.000000e+01                7.000000e+01\n",
      "75%    3.361508e+07   1.035100e+04  5.210000e+02       0.000000e+00  9.605920e+06  2.196670e+05  1.098144e+03   1.830241e+01     1.116810e+00       -1.000000e+00        -1.000000e+00  7.503950e+02      9.100000e+01                9.100000e+01\n",
      "max    4.482011e+07   1.413100e+04  9.260000e+02       8.000000e+00  1.311449e+07  3.944270e+05  1.499938e+03   2.499897e+01     1.228664e+00        9.000000e+02         9.250000e+02  1.699987e+03      3.688400e+04                3.688400e+04\n",
      "\n",
      "12. 重复行分析:\n",
      "   重复行数量: 0\n",
      "   重复行比例: 0.00%\n",
      "\n",
      "13. 特殊值检查:\n",
      "\n",
      "================================================================================\n",
      "分析完成!\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "质谱数据特定分析\n",
      "================================================================================\n",
      "\n",
      "可能的质谱相关列:\n",
      "   发现可能的质谱列: frame_indices\n",
      "   发现可能的质谱列: scan_indices\n",
      "   发现可能的质谱列: rt_values\n",
      "   发现可能的质谱列: rt_values_min\n",
      "   发现可能的质谱列: mobility_values\n",
      "   发现可能的质谱列: quad_low_mz_values\n",
      "   发现可能的质谱列: quad_high_mz_values\n",
      "   发现可能的质谱列: mz_values\n",
      "   发现可能的质谱列: intensity_values\n",
      "   发现可能的质谱列: corrected_intensity_values\n",
      "\n",
      "数值列统计摘要:\n",
      "   总共 14 个数值列\n",
      "   数据范围最大的列: raw_indices (范围: 44820113.000000)\n",
      "   数据范围最小的列: mobility_values (范围: 0.577371)\n",
      "\n",
      "数据分布特征:\n",
      "   是否包含负值: True\n",
      "   是否包含零值: True\n",
      "\n",
      "原始 TimsTOF 对象信息:\n",
      "   对象类型: <class 'timstof_PASEF_20250506.TimsTOF'>\n",
      "   公共属性数量: 55\n",
      "   主要属性: ['accumulation_times', 'acquisition_mode', 'as_dataframe', 'bin_intensities', 'bruker_d_folder_name', 'calculate_global_calibrated_mz_values', 'calibrated_mz_max_value', 'calibrated_mz_min_value', 'calibrated_mz_values', 'convert_from_indices']\n",
      "   ... 还有 45 个属性\n",
      "\n",
      "   TimsTOF 对象的字符串表示:\n",
      "   <timstof_PASEF_20250506.TimsTOF object at 0x113888940>...\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def print_df_detailed_info(df, df_name=\"DataFrame\"):\n",
    "    \"\"\"\n",
    "    详细打印 DataFrame 的所有相关信息\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"详细分析 {df_name}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. 基本信息\n",
    "    print(\"\\n1. 基本信息:\")\n",
    "    print(f\"   数据类型: {type(df)}\")\n",
    "    print(f\"   形状 (行数, 列数): {df.shape}\")\n",
    "    print(f\"   总元素数量: {df.size}\")\n",
    "    print(f\"   维度: {df.ndim}\")\n",
    "    \n",
    "    # 2. 列信息\n",
    "    print(\"\\n2. 列信息:\")\n",
    "    print(f\"   列数量: {len(df.columns)}\")\n",
    "    print(f\"   列名称: {list(df.columns)}\")\n",
    "    \n",
    "    # 3. 索引信息\n",
    "    print(\"\\n3. 索引信息:\")\n",
    "    print(f\"   索引类型: {type(df.index)}\")\n",
    "    print(f\"   索引范围: {df.index.min()} 到 {df.index.max()}\")\n",
    "    print(f\"   索引名称: {df.index.name}\")\n",
    "    \n",
    "    # 4. 数据类型分析\n",
    "    print(\"\\n4. 数据类型详情:\")\n",
    "    dtype_counts = df.dtypes.value_counts()\n",
    "    for dtype, count in dtype_counts.items():\n",
    "        print(f\"   {dtype}: {count} 列\")\n",
    "    \n",
    "    print(\"\\n   各列数据类型:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"   {col}: {df[col].dtype}\")\n",
    "    \n",
    "    # 5. 缺失值分析\n",
    "    print(\"\\n5. 缺失值分析:\")\n",
    "    missing_data = df.isnull().sum()\n",
    "    total_missing = missing_data.sum()\n",
    "    print(f\"   总缺失值: {total_missing}\")\n",
    "    print(f\"   缺失值比例: {total_missing / df.size * 100:.2f}%\")\n",
    "    \n",
    "    if total_missing > 0:\n",
    "        print(\"   各列缺失值详情:\")\n",
    "        for col in df.columns:\n",
    "            missing_count = missing_data[col]\n",
    "            missing_percent = missing_count / len(df) * 100\n",
    "            if missing_count > 0:\n",
    "                print(f\"   {col}: {missing_count} ({missing_percent:.2f}%)\")\n",
    "    \n",
    "    # 6. 内存使用情况\n",
    "    print(\"\\n6. 内存使用情况:\")\n",
    "    memory_usage = df.memory_usage(deep=True)\n",
    "    total_memory = memory_usage.sum()\n",
    "    print(f\"   总内存使用: {total_memory / 1024 / 1024:.2f} MB\")\n",
    "    print(\"   各列内存使用:\")\n",
    "    for col in df.columns:\n",
    "        col_memory = memory_usage[col] / 1024 / 1024\n",
    "        print(f\"   {col}: {col_memory:.2f} MB\")\n",
    "    \n",
    "    # 7. 数值列统计信息\n",
    "    print(\"\\n7. 数值列统计信息:\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"   数值列数量: {len(numeric_cols)}\")\n",
    "        for col in numeric_cols:\n",
    "            print(f\"\\n   {col}:\")\n",
    "            series = df[col]\n",
    "            print(f\"     最小值: {series.min()}\")\n",
    "            print(f\"     最大值: {series.max()}\")\n",
    "            print(f\"     平均值: {series.mean():.6f}\")\n",
    "            print(f\"     中位数: {series.median():.6f}\")\n",
    "            print(f\"     标准差: {series.std():.6f}\")\n",
    "            print(f\"     非零值数量: {(series != 0).sum()}\")\n",
    "            print(f\"     唯一值数量: {series.nunique()}\")\n",
    "    else:\n",
    "        print(\"   没有数值列\")\n",
    "    \n",
    "    # 8. 非数值列信息\n",
    "    print(\"\\n8. 非数值列信息:\")\n",
    "    non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "    if len(non_numeric_cols) > 0:\n",
    "        print(f\"   非数值列数量: {len(non_numeric_cols)}\")\n",
    "        for col in non_numeric_cols:\n",
    "            print(f\"\\n   {col}:\")\n",
    "            series = df[col]\n",
    "            print(f\"     数据类型: {series.dtype}\")\n",
    "            print(f\"     唯一值数量: {series.nunique()}\")\n",
    "            print(f\"     最常见的值: {series.mode().iloc[0] if not series.mode().empty else 'N/A'}\")\n",
    "            if series.nunique() <= 10:\n",
    "                print(f\"     所有唯一值: {list(series.unique())}\")\n",
    "    else:\n",
    "        print(\"   没有非数值列\")\n",
    "    \n",
    "    # 9. 前几行数据预览\n",
    "    print(\"\\n9. 数据预览:\")\n",
    "    print(\"   前5行:\")\n",
    "    print(df.head().to_string())\n",
    "    \n",
    "    print(\"\\n   后5行:\")\n",
    "    print(df.tail().to_string())\n",
    "    \n",
    "    # 10. DataFrame.info() 输出\n",
    "    print(\"\\n10. DataFrame.info() 详情:\")\n",
    "    df.info(verbose=True, memory_usage='deep')\n",
    "    \n",
    "    # 11. 描述性统计\n",
    "    print(\"\\n11. 描述性统计:\")\n",
    "    try:\n",
    "        print(df.describe(include='all').to_string())\n",
    "    except Exception as e:\n",
    "        print(f\"   无法生成描述性统计: {e}\")\n",
    "    \n",
    "    # 12. 重复行分析\n",
    "    print(\"\\n12. 重复行分析:\")\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    print(f\"   重复行数量: {duplicate_rows}\")\n",
    "    print(f\"   重复行比例: {duplicate_rows / len(df) * 100:.2f}%\")\n",
    "    \n",
    "    # 13. 特殊值检查（针对数值列）\n",
    "    print(\"\\n13. 特殊值检查:\")\n",
    "    for col in numeric_cols:\n",
    "        series = df[col]\n",
    "        inf_count = np.isinf(series).sum()\n",
    "        neg_inf_count = np.isneginf(series).sum()\n",
    "        if inf_count > 0 or neg_inf_count > 0:\n",
    "            print(f\"   {col}: {inf_count} 个正无穷值, {neg_inf_count} 个负无穷值\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"分析完成!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 返回一些有用的信息供后续使用\n",
    "    return {\n",
    "        'numeric_cols': numeric_cols,\n",
    "        'non_numeric_cols': non_numeric_cols,\n",
    "        'shape': df.shape,\n",
    "        'memory_mb': total_memory / 1024 / 1024\n",
    "    }\n",
    "\n",
    "# 使用函数分析你的 DataFrame\n",
    "analysis_result = print_df_detailed_info(df, \"TimsTOF 质谱数据\")\n",
    "\n",
    "# 额外的质谱数据特定分析\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"质谱数据特定分析\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 如果数据包含常见的质谱列，进行特定分析\n",
    "potential_ms_columns = ['mz', 'm/z', 'mass', 'intensity', 'rt', 'retention_time', \n",
    "                       'mobility', 'ccs', 'charge', 'scan', 'frame']\n",
    "\n",
    "print(\"\\n可能的质谱相关列:\")\n",
    "ms_related_cols = []\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    for ms_col in potential_ms_columns:\n",
    "        if ms_col in col_lower:\n",
    "            print(f\"   发现可能的质谱列: {col}\")\n",
    "            ms_related_cols.append(col)\n",
    "            break\n",
    "\n",
    "if not ms_related_cols:\n",
    "    print(\"   未发现明显的质谱相关列名\")\n",
    "\n",
    "# 使用分析结果中的numeric_cols\n",
    "numeric_cols = analysis_result['numeric_cols']\n",
    "non_numeric_cols = analysis_result['non_numeric_cols']\n",
    "\n",
    "# 如果有数值数据，进行额外分析\n",
    "if len(numeric_cols) > 0:\n",
    "    print(f\"\\n数值列统计摘要:\")\n",
    "    print(f\"   总共 {len(numeric_cols)} 个数值列\")\n",
    "    \n",
    "    # 找到数值范围最大和最小的列\n",
    "    max_ranges = {}\n",
    "    min_vals = {}\n",
    "    max_vals = {}\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        series = df[col]\n",
    "        min_val = series.min()\n",
    "        max_val = series.max()\n",
    "        range_val = max_val - min_val\n",
    "        \n",
    "        max_ranges[col] = range_val\n",
    "        min_vals[col] = min_val\n",
    "        max_vals[col] = max_val\n",
    "    \n",
    "    largest_range_col = max(max_ranges, key=max_ranges.get)\n",
    "    smallest_range_col = min(max_ranges, key=max_ranges.get)\n",
    "    \n",
    "    print(f\"   数据范围最大的列: {largest_range_col} (范围: {max_ranges[largest_range_col]:.6f})\")\n",
    "    print(f\"   数据范围最小的列: {smallest_range_col} (范围: {max_ranges[smallest_range_col]:.6f})\")\n",
    "else:\n",
    "    print(f\"\\n没有数值列可供分析\")\n",
    "\n",
    "# 检查数据的分布特征\n",
    "print(f\"\\n数据分布特征:\")\n",
    "if len(numeric_cols) > 0:\n",
    "    has_negative = (df[numeric_cols] < 0).any().any()\n",
    "    has_zero = (df[numeric_cols] == 0).any().any()\n",
    "    print(f\"   是否包含负值: {has_negative}\")\n",
    "    print(f\"   是否包含零值: {has_zero}\")\n",
    "else:\n",
    "    print(\"   没有数值列，无法检查数值分布特征\")\n",
    "\n",
    "# 打印原始数据对象的额外信息\n",
    "print(f\"\\n原始 TimsTOF 对象信息:\")\n",
    "print(f\"   对象类型: {type(timstof_data)}\")\n",
    "try:\n",
    "    # 获取对象的主要属性（过滤掉私有属性）\n",
    "    public_attrs = [attr for attr in dir(timstof_data) if not attr.startswith('_')]\n",
    "    print(f\"   公共属性数量: {len(public_attrs)}\")\n",
    "    print(f\"   主要属性: {public_attrs[:10]}\")  # 只显示前10个\n",
    "    if len(public_attrs) > 10:\n",
    "        print(f\"   ... 还有 {len(public_attrs) - 10} 个属性\")\n",
    "except:\n",
    "    print(\"   无法获取对象属性\")\n",
    "\n",
    "# 尝试获取更多关于TimsTOF对象的信息\n",
    "try:\n",
    "    print(f\"\\n   TimsTOF 对象的字符串表示:\")\n",
    "    print(f\"   {str(timstof_data)[:200]}...\")  # 只显示前200个字符\n",
    "except:\n",
    "    print(\"   无法获取对象的字符串表示\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r_/1rx2ntgs4296v4jr0jc9bptw0000gn/T/ipykernel_10227/2924228296.py:72: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  library['FragmentType'] = library['FragmentType'].replace(replacement_dict)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "library = pd.read_csv(\"/Users/augustsirius/Desktop/DIABERT_test_code_lib/helper/lib/TPHPlib_frag1025_swissprot_final_all_from_Yueliang.tsv\", sep=\"\\t\")\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_lib_col_dict():\n",
    "    lib_col_dict = defaultdict(str)\n",
    "\n",
    "    for key in ['transition_group_id', 'PrecursorID']:\n",
    "        lib_col_dict[key] = 'transition_group_id'\n",
    "\n",
    "    for key in ['PeptideSequence', 'Sequence', 'StrippedPeptide']:\n",
    "        lib_col_dict[key] = 'PeptideSequence'\n",
    "\n",
    "    for key in ['FullUniModPeptideName', 'ModifiedPeptide', 'LabeledSequence', 'modification_sequence',\n",
    "                'ModifiedPeptideSequence']:\n",
    "        lib_col_dict[key] = 'FullUniModPeptideName'\n",
    "\n",
    "    for key in ['PrecursorCharge', 'Charge', 'prec_z']:\n",
    "        lib_col_dict[key] = 'PrecursorCharge'\n",
    "\n",
    "    for key in ['PrecursorMz', 'Q1']:\n",
    "        lib_col_dict[key] = 'PrecursorMz'\n",
    "\n",
    "    for key in ['Tr_recalibrated', 'iRT', 'RetentionTime', 'NormalizedRetentionTime', 'RT_detected']:\n",
    "        lib_col_dict[key] = 'Tr_recalibrated'\n",
    "\n",
    "    for key in ['ProductMz', 'FragmentMz', 'Q3']:\n",
    "        lib_col_dict[key] = 'ProductMz'\n",
    "\n",
    "    for key in ['FragmentType', 'FragmentIonType', 'ProductType', 'ProductIonType', 'frg_type']:\n",
    "        lib_col_dict[key] = 'FragmentType'\n",
    "\n",
    "    for key in ['FragmentCharge', 'FragmentIonCharge', 'ProductCharge', 'ProductIonCharge', 'frg_z']:\n",
    "        lib_col_dict[key] = 'FragmentCharge'\n",
    "\n",
    "    for key in ['FragmentNumber', 'frg_nr', 'FragmentSeriesNumber']:\n",
    "        lib_col_dict[key] = 'FragmentNumber'\n",
    "\n",
    "    for key in ['LibraryIntensity', 'RelativeIntensity', 'RelativeFragmentIntensity', 'RelativeFragmentIonIntensity',\n",
    "                'relative_intensity']:\n",
    "        lib_col_dict[key] = 'LibraryIntensity'\n",
    "\n",
    "    # exclude\n",
    "    for key in ['FragmentLossType', 'FragmentIonLossType', 'ProductLossType', 'ProductIonLossType']:\n",
    "        lib_col_dict[key] = 'FragmentLossType'\n",
    "\n",
    "    for key in ['ProteinID', 'ProteinId', 'UniprotID', 'uniprot_id', 'UniProtIds']:\n",
    "        lib_col_dict[key] = 'ProteinID'\n",
    "\n",
    "    for key in ['ProteinName', 'Protein Name', 'Protein_name', 'protein_name']:\n",
    "        lib_col_dict[key] = 'ProteinName'\n",
    "\n",
    "    for key in ['Gene', 'Genes', 'GeneName']:\n",
    "        lib_col_dict[key] = 'Gene'\n",
    "\n",
    "    for key in ['Decoy', 'decoy']:\n",
    "        lib_col_dict[key] = 'decoy'\n",
    "\n",
    "    for key in ['ExcludeFromAssay', 'ExcludeFromQuantification']:\n",
    "        lib_col_dict[key] = 'ExcludeFromAssay'\n",
    "    return lib_col_dict\n",
    "\n",
    "# col mapping\n",
    "lib_col_dict = get_lib_col_dict()\n",
    "for col in set(library.columns) & set(lib_col_dict.keys()):\n",
    "    library.loc[:, lib_col_dict[col]] = library.loc[:, col]\n",
    "\n",
    "library['transition_group_id'] = library['FullUniModPeptideName'] + library['PrecursorCharge'].astype(str)\n",
    "replacement_dict = {'b': 1, 'y': 2, 'p': 3}\n",
    "library['FragmentType'] = library['FragmentType'].replace(replacement_dict)\n",
    "library['decoy'] = 0\n",
    "precursor_id_list = [\"AAAAAAALQAK2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cpu'\n",
    "frag_repeat_num = 5\n",
    "\n",
    "report_diann = pd.read_parquet('/Users/augustsirius/Desktop/DIABERT_test_code_lib/helper/report/report.parquet')\n",
    "report_diann['transition_group_id'] = report_diann['Precursor.Id']\n",
    "\n",
    "diann_result = pd.merge(library[['transition_group_id', 'PrecursorMz', 'ProductMz']], report_diann[['transition_group_id', 'RT', 'IM','iIM']], on='transition_group_id', how='left').dropna(subset=['RT'])\n",
    "\n",
    "diann_precursor_id_all = diann_result.drop_duplicates(subset=['transition_group_id'])[['transition_group_id', 'RT', 'IM']].reset_index(drop=True)\n",
    "\n",
    "assay_rt_kept_dict = dict(zip(diann_precursor_id_all['transition_group_id'], diann_precursor_id_all['RT']))\n",
    "assay_im_kept_dict = dict(zip(diann_precursor_id_all['transition_group_id'], diann_precursor_id_all['IM']))\n",
    "\n",
    "each_lib_data = library[library['transition_group_id'].isin(precursor_id_list)]\n",
    "precursors_list, ms1_data_list, ms2_data_list, precursor_info_list = utils.build_lib_matrix(\n",
    "            each_lib_data,\n",
    "            utils.lib_cols,\n",
    "            None,\n",
    "            None,\n",
    "            5,\n",
    "            1801,\n",
    "            20,\n",
    "            None)\n",
    "ms1_data_tensor, ms2_data_tensor = utils.build_precursors_matrix_step1(ms1_data_list, ms2_data_list, device)\n",
    "ms2_data_tensor = utils.build_precursors_matrix_step2(ms2_data_tensor)\n",
    "ms1_range_list, ms2_range_list = utils.build_range_matrix_step3(ms1_data_tensor, ms2_data_tensor, frag_repeat_num, device=device)\n",
    "ms1_data_tensor, ms2_data_tensor, ms1_extract_width_range_list, ms2_extract_width_range_list = utils.build_precursors_matrix_step3(ms1_data_tensor, ms2_data_tensor, frag_repeat_num, device=device)\n",
    "\n",
    "precursor_info_np_org = np.array(precursor_info_list)\n",
    "precursor_info_choose = precursor_info_np_org[:, 0: 5]\n",
    "delta_rt_kept = np.array([0] * len(precursor_info_choose)).reshape(-1, 1)\n",
    "\n",
    "assay_rt_kept = np.array([assay_rt_kept_dict[ee[0]] for ee in precursors_list]).reshape(-1, 1)\n",
    "assay_im_kept = np.array([assay_im_kept_dict[ee[0]] for ee in precursors_list]).reshape(-1, 1)\n",
    "\n",
    "# precursor_feat\n",
    "precursor_feat = np.column_stack([precursor_info_choose, assay_im_kept, assay_rt_kept, delta_rt_kept])\n",
    "# frag info\n",
    "frag_info = utils.build_frag_info(ms1_data_tensor, ms2_data_tensor, frag_repeat_num,\n",
    "                                device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
