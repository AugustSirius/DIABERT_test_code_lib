#!/usr/bin/env python3
# tolerance_compare_results.py
# å®¹å·®ç‰ˆæœ¬çš„ç»“æœæ¯”è¾ƒå™¨ï¼Œè€ƒè™‘f32/f64æµ®ç‚¹ç²¾åº¦å·®å¼‚ï¼Œå¸¦è¿›åº¦æ¡

import json
import os
import glob
import numpy as np
from typing import Dict, List, Tuple, Set
import pandas as pd
from datetime import datetime
from tqdm import tqdm
from scipy.spatial import cKDTree


class ToleranceResultComparator:
    def __init__(self, result_dir: str):
        self.result_dir = result_dir
        self.results = {}
        
        # è®¾ç½®å®¹å·®å‚æ•°
        self.tolerances = {
            'mz_ppm': 5.0,           # m/zç›¸å¯¹è¯¯å·® 5 ppm
            'rt_seconds': 0.1,       # RTå®¹å·® 0.1ç§’  
            'mobility_relative': 0.001,  # mobilityç›¸å¯¹è¯¯å·® 0.1%
            'intensity_relative': 0.01,  # å¼ºåº¦ç›¸å¯¹è¯¯å·® 1%
            'range_relative': 0.0001     # èŒƒå›´ç›¸å¯¹è¯¯å·® 0.01%
        }
        
    def load_results(self):
        """åŠ è½½æ‰€æœ‰JSONç»“æœæ–‡ä»¶"""
        json_files = glob.glob(os.path.join(self.result_dir, "*.json"))
        
        print("æ­£åœ¨åŠ è½½æ•°æ®æ–‡ä»¶...")
        for file_path in tqdm(json_files, desc="åŠ è½½JSONæ–‡ä»¶"):
            # è·³è¿‡æ¯”è¾ƒæŠ¥å‘Šæ–‡ä»¶
            if 'comparison_report' in os.path.basename(file_path) or 'tolerance_comparison' in os.path.basename(file_path):
                continue
                
            try:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                
                # ç¡®ä¿æ˜¯æ•°æ®æ–‡ä»¶è€Œä¸æ˜¯æŠ¥å‘Šæ–‡ä»¶
                if not all(key in data for key in ['version', 'precursor_id', 'ms1_data', 'ms2_data']):
                    continue
                    
                key = (data['version'], data['precursor_id'])
                if key not in self.results:
                    self.results[key] = []
                self.results[key].append(data)
                
            except Exception as e:
                print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                continue
        
        data_files_count = sum(len(files) for files in self.results.values())
        print(f"åŠ è½½äº† {data_files_count} ä¸ªæ•°æ®æ–‡ä»¶")
        
    def find_matching_pairs(self) -> List[Tuple[Dict, Dict]]:
        """æ‰¾åˆ°åŸå§‹ç‰ˆæœ¬å’Œä¼˜åŒ–ç‰ˆæœ¬çš„é…å¯¹ç»“æœ"""
        pairs = []
        
        precursor_ids = set()
        for (version, precursor_id) in self.results.keys():
            precursor_ids.add(precursor_id)
        
        for precursor_id in precursor_ids:
            original_key = ('original', precursor_id)
            optimized_key = ('optimized', precursor_id)
            
            if original_key in self.results and optimized_key in self.results:
                original = sorted(self.results[original_key], 
                                key=lambda x: x['timestamp'], reverse=True)[0]
                optimized = sorted(self.results[optimized_key], 
                                 key=lambda x: x['timestamp'], reverse=True)[0]
                pairs.append((original, optimized))
        
        return pairs
    
    def _values_match_with_tolerance(self, val1: float, val2: float, 
                                   tolerance_type: str, reference_val: float = None) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªå€¼æ˜¯å¦åœ¨å®¹å·®èŒƒå›´å†…åŒ¹é…"""
        if tolerance_type == 'mz_ppm':
            # ppm = |val1 - val2| / reference_val * 1e6
            ref = reference_val if reference_val is not None else max(abs(val1), abs(val2))
            if ref == 0:
                return abs(val1 - val2) < 1e-10
            ppm_diff = abs(val1 - val2) / ref * 1e6
            return ppm_diff <= self.tolerances['mz_ppm']
            
        elif tolerance_type == 'rt_seconds':
            return abs(val1 - val2) <= self.tolerances['rt_seconds']
            
        elif tolerance_type == 'mobility_relative':
            ref = max(abs(val1), abs(val2))
            if ref == 0:
                return abs(val1 - val2) < 1e-10
            return abs(val1 - val2) / ref <= self.tolerances['mobility_relative']
            
        elif tolerance_type == 'intensity_relative':
            ref = max(abs(val1), abs(val2))
            if ref == 0:
                return abs(val1 - val2) < 1e-10
            return abs(val1 - val2) / ref <= self.tolerances['intensity_relative']
            
        elif tolerance_type == 'range_relative':
            ref = max(abs(val1), abs(val2))
            if ref == 0:
                return abs(val1 - val2) < 1e-10
            return abs(val1 - val2) / ref <= self.tolerances['range_relative']
            
        return False
    
    def _ranges_match_with_tolerance(self, range1: List[float], range2: List[float]) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªèŒƒå›´æ˜¯å¦åœ¨å®¹å·®å†…åŒ¹é…"""
        if len(range1) != len(range2) or len(range1) != 2:
            return False
        
        return (self._values_match_with_tolerance(range1[0], range2[0], 'range_relative') and
                self._values_match_with_tolerance(range1[1], range2[1], 'range_relative'))
    
    # def _find_matching_data_points(self, data1: Dict, data2: Dict, data_type: str) -> Tuple[Set, Set, Set, List]:
    #     """æ‰¾åˆ°åŒ¹é…çš„æ•°æ®ç‚¹ï¼Œè¿”å›(åŒ¹é…çš„ç´¢å¼•å¯¹, ä»…åœ¨data1ä¸­çš„ç´¢å¼•, ä»…åœ¨data2ä¸­çš„ç´¢å¼•, å¼ºåº¦å·®å¼‚åˆ—è¡¨)"""
        
    #     if len(data1['mz_values']) == 0 or len(data2['mz_values']) == 0:
    #         return set(), set(range(len(data1['mz_values']))), set(range(len(data2['mz_values']))), []
        
    #     # ä¸ºdata2å»ºç«‹ç´¢å¼•ä»¥åŠ é€ŸæŸ¥æ‰¾
    #     data2_available = set(range(len(data2['mz_values'])))
        
    #     matched_pairs = set()
    #     intensity_diffs = []
        
    #     # æ·»åŠ è¿›åº¦æ¡ï¼Œæ˜¾ç¤ºæ•°æ®ç‚¹åŒ¹é…è¿›åº¦
    #     desc = f"åŒ¹é…{data_type}æ•°æ®ç‚¹"
    #     for i in tqdm(range(len(data1['mz_values'])), desc=desc, leave=False):
    #         mz1 = data1['mz_values'][i]
    #         rt1 = data1['rt_values'][i]
    #         mob1 = data1['mobility_values'][i]
    #         int1 = data1['intensity_values'][i]
            
    #         # åœ¨data2ä¸­å¯»æ‰¾åŒ¹é…ç‚¹
    #         best_match = None
    #         best_match_idx = None
            
    #         for j in list(data2_available):  # å¤åˆ¶é›†åˆä»¥é¿å…ä¿®æ”¹æ—¶å‡ºé”™
    #             mz2 = data2['mz_values'][j]
    #             rt2 = data2['rt_values'][j]
    #             mob2 = data2['mobility_values'][j]
    #             int2 = data2['intensity_values'][j]
                
    #             # æ£€æŸ¥æ˜¯å¦åŒ¹é…
    #             if (self._values_match_with_tolerance(mz1, mz2, 'mz_ppm', mz1) and
    #                 self._values_match_with_tolerance(rt1, rt2, 'rt_seconds') and
    #                 self._values_match_with_tolerance(mob1, mob2, 'mobility_relative')):
                    
    #                 best_match = (i, j)
    #                 best_match_idx = j
                    
    #                 # æ£€æŸ¥å¼ºåº¦å·®å¼‚
    #                 if not self._values_match_with_tolerance(int1, int2, 'intensity_relative'):
    #                     intensity_diffs.append(abs(int1 - int2))
                    
    #                 break
            
    #         if best_match:
    #             matched_pairs.add(best_match)
    #             data2_available.remove(best_match_idx)
        
    #     # è·å–æœªåŒ¹é…çš„ç´¢å¼•
    #     matched_data1_indices = {pair[0] for pair in matched_pairs}
    #     matched_data2_indices = {pair[1] for pair in matched_pairs}
        
    #     unmatched_data1 = set(range(len(data1['mz_values']))) - matched_data1_indices
    #     unmatched_data2 = set(range(len(data2['mz_values']))) - matched_data2_indices
        
    #     return matched_pairs, unmatched_data1, unmatched_data2, intensity_diffs

    def _find_matching_data_points(self, data1: Dict, data2: Dict, data_type: str) -> Tuple[Set, Set, Set, List]:
        """ä½¿ç”¨KD-Treeä¼˜åŒ–çš„æ•°æ®ç‚¹åŒ¹é…"""
        
        if len(data1['mz_values']) == 0 or len(data2['mz_values']) == 0:
            return set(), set(range(len(data1['mz_values']))), set(range(len(data2['mz_values']))), []
        
        # é¦–å…ˆè½¬æ¢ä¸ºNumPyæ•°ç»„
        mz1 = np.array(data1['mz_values'])
        rt1 = np.array(data1['rt_values'])
        mob1 = np.array(data1['mobility_values'])
        int1 = np.array(data1['intensity_values'])
        
        mz2 = np.array(data2['mz_values'])
        rt2 = np.array(data2['rt_values'])
        mob2 = np.array(data2['mobility_values'])
        int2 = np.array(data2['intensity_values'])
        
        n1 = len(mz1)
        n2 = len(mz2)
        
        # è®¡ç®—å½’ä¸€åŒ–å°ºåº¦
        # ä½¿ç”¨æ•°æ®çš„å¹³å‡å€¼æ¥ä¼°ç®—å°ºåº¦
        mz_scale = np.mean(mz1) * self.tolerances['mz_ppm'] / 1e6
        rt_scale = self.tolerances['rt_seconds']
        mob_mean = np.mean(mob1)
        if mob_mean > 0:
            mobility_scale = mob_mean * self.tolerances['mobility_relative']
        else:
            mobility_scale = 0.001  # é˜²æ­¢é™¤é›¶
        
        # æ„å»ºç‰¹å¾çŸ©é˜µ
        features1 = np.column_stack([
            mz1 / mz_scale,
            rt1 / rt_scale,
            mob1 / mobility_scale if mobility_scale > 0 else mob1
        ])
        
        features2 = np.column_stack([
            mz2 / mz_scale,
            rt2 / rt_scale,
            mob2 / mobility_scale if mobility_scale > 0 else mob2
        ])
        
        # æ„å»ºKD-Tree
        from scipy.spatial import cKDTree
        tree = cKDTree(features2)
        
        matched_pairs = set()
        intensity_diffs = []
        data2_used = set()
        
        # ä½¿ç”¨KD-TreeæŸ¥æ‰¾æœ€è¿‘é‚»
        desc = f"åŒ¹é…{data_type}æ•°æ®ç‚¹"
        for i in tqdm(range(n1), desc=desc, leave=False):
            # æŸ¥æ‰¾åŠå¾„å†…çš„æ‰€æœ‰ç‚¹
            indices = tree.query_ball_point(features1[i], r=1.0)
            
            if indices:
                # åœ¨å€™é€‰ç‚¹ä¸­æ‰¾æœ€è¿‘çš„æœªä½¿ç”¨ç‚¹
                best_j = None
                best_dist = float('inf')
                
                for j in indices:
                    if j not in data2_used:
                        # å†æ¬¡éªŒè¯æ˜¯å¦çœŸçš„åŒ¹é…ï¼ˆå› ä¸ºKD-Treeä½¿ç”¨çš„æ˜¯æ¬§å¼è·ç¦»ï¼‰
                        if (self._values_match_with_tolerance(mz1[i], mz2[j], 'mz_ppm', mz1[i]) and
                            self._values_match_with_tolerance(rt1[i], rt2[j], 'rt_seconds') and
                            self._values_match_with_tolerance(mob1[i], mob2[j], 'mobility_relative')):
                            
                            dist = np.linalg.norm(features1[i] - features2[j])
                            if dist < best_dist:
                                best_dist = dist
                                best_j = j
                
                if best_j is not None:
                    matched_pairs.add((i, best_j))
                    data2_used.add(best_j)
                    
                    # æ£€æŸ¥å¼ºåº¦å·®å¼‚
                    if not self._values_match_with_tolerance(int1[i], int2[best_j], 'intensity_relative'):
                        intensity_diffs.append(abs(int1[i] - int2[best_j]))
        
        # è·å–æœªåŒ¹é…çš„ç´¢å¼•
        matched_data1_indices = {pair[0] for pair in matched_pairs}
        matched_data2_indices = {pair[1] for pair in matched_pairs}
        
        unmatched_data1 = set(range(n1)) - matched_data1_indices
        unmatched_data2 = set(range(n2)) - matched_data2_indices
        
        return matched_pairs, unmatched_data1, unmatched_data2, intensity_diffs

    def _compare_ms_data_with_tolerance(self, data1: Dict, data2: Dict, data_type: str) -> Dict:
        """ä½¿ç”¨å®¹å·®æ¯”è¾ƒMSæ•°æ®"""
        result = {
            'data_type': data_type,
            'data_points_original': data1['data_points'],
            'data_points_optimized': data2['data_points'],
            'data_points_diff': data1['data_points'] - data2['data_points'],
        }
        
        if data_type == 'MS2':
            result['num_fragments_original'] = data1['num_fragments']
            result['num_fragments_optimized'] = data2['num_fragments']
            result['fragments_diff'] = data1['num_fragments'] - data2['num_fragments']
        
        if data1['data_points'] > 0 and data2['data_points'] > 0:
            print(f"  æ­£åœ¨æ¯”è¾ƒ{data_type}æ•°æ®...")
            matched_pairs, unmatched_1, unmatched_2, intensity_diffs = \
                self._find_matching_data_points(data1, data2, data_type)
            
            result['matched_points'] = len(matched_pairs)
            result['unmatched_in_original'] = len(unmatched_1)
            result['unmatched_in_optimized'] = len(unmatched_2)
            result['intensity_differences_count'] = len(intensity_diffs)
            result['max_intensity_diff'] = max(intensity_diffs) if intensity_diffs else 0
            result['mean_intensity_diff'] = np.mean(intensity_diffs) if intensity_diffs else 0
            
            # è®¡ç®—åŒ¹é…ç‡
            total_points = max(data1['data_points'], data2['data_points'])
            result['match_rate'] = len(matched_pairs) / total_points if total_points > 0 else 0
            
            # è¯„ä¼°æ•°æ®è´¨é‡
            if len(matched_pairs) > 0:
                intensity_diff_rate = result['intensity_differences_count'] / len(matched_pairs)
            else:
                intensity_diff_rate = 0
                
            if result['match_rate'] > 0.95 and intensity_diff_rate < 0.01:
                result['quality_assessment'] = 'ä¼˜ç§€'
            elif result['match_rate'] > 0.90 and intensity_diff_rate < 0.05:
                result['quality_assessment'] = 'è‰¯å¥½'
            elif result['match_rate'] > 0.80:
                result['quality_assessment'] = 'ä¸€èˆ¬'
            else:
                result['quality_assessment'] = 'å·®'
                
            print(f"  {data_type}æ•°æ®æ¯”è¾ƒå®Œæˆ: åŒ¹é…ç‡ {result['match_rate']:.3f}, è´¨é‡è¯„ä¼°: {result['quality_assessment']}")
        else:
            result['quality_assessment'] = 'æ— æ•°æ®'
        
        return result
    
    def compare_slice_results(self, original: Dict, optimized: Dict) -> Dict:
        """ä½¿ç”¨å®¹å·®æ¯”è¾ƒä¸¤ä¸ªç‰ˆæœ¬çš„åˆ‡ç‰‡ç»“æœ"""
        comparison = {
            'precursor_id': original['precursor_id'],
            'timestamps': {
                'original': original['timestamp'],
                'optimized': optimized['timestamp']
            },
            'tolerances_used': self.tolerances
        }
        
        # æ¯”è¾ƒèŒƒå›´
        ms1_orig, ms1_opt = original['ms1_data'], optimized['ms1_data']
        ms2_orig, ms2_opt = original['ms2_data'], optimized['ms2_data']
        
        print(f"æ­£åœ¨æ¯”è¾ƒèŒƒå›´...")
        comparison['range_comparison'] = {
            'mz_range_match': self._ranges_match_with_tolerance(
                ms1_orig['mz_range'], ms1_opt['mz_range']),
            'im_range_match': self._ranges_match_with_tolerance(
                ms1_orig['im_range'], ms1_opt['im_range']),
            'mz_range_original': ms1_orig['mz_range'],
            'mz_range_optimized': ms1_opt['mz_range'],
            'im_range_original': ms1_orig['im_range'],
            'im_range_optimized': ms1_opt['im_range']
        }
        
        # æ¯”è¾ƒMSæ•°æ®
        comparison['ms1_comparison'] = self._compare_ms_data_with_tolerance(
            ms1_orig, ms1_opt, 'MS1')
        comparison['ms2_comparison'] = self._compare_ms_data_with_tolerance(
            ms2_orig, ms2_opt, 'MS2')
        
        return comparison
    
    def generate_report(self):
        """ç”Ÿæˆå®¹å·®æ¯”è¾ƒæŠ¥å‘Š"""
        print("=== å¼€å§‹ç”Ÿæˆå®¹å·®æ¯”è¾ƒæŠ¥å‘Š ===\n")
        
        self.load_results()
        pairs = self.find_matching_pairs()
        
        if not pairs:
            print("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„åŸå§‹ç‰ˆæœ¬å’Œä¼˜åŒ–ç‰ˆæœ¬ç»“æœå¯¹")
            return
        
        print(f"\næ‰¾åˆ° {len(pairs)} å¯¹åŒ¹é…ç»“æœ")
        print(f"ä½¿ç”¨çš„å®¹å·®è®¾ç½®:")
        for key, value in self.tolerances.items():
            print(f"  {key}: {value}")
        print("\n")
        
        all_comparisons = []
        
        # æ·»åŠ ä¸»è¦æ¯”è¾ƒè¿›åº¦æ¡
        for original, optimized in tqdm(pairs, desc="æ¯”è¾ƒå‰ä½“åˆ‡ç‰‡ç»“æœ"):
            print(f"\n=== æ­£åœ¨å¤„ç† Precursor: {original['precursor_id']} ===")
            comparison = self.compare_slice_results(original, optimized)
            all_comparisons.append(comparison)
            
            print(f"=== Precursor: {comparison['precursor_id']} ===")
            print(f"æ—¶é—´æˆ³:")
            print(f"  åŸå§‹ç‰ˆæœ¬: {comparison['timestamps']['original']}")
            print(f"  ä¼˜åŒ–ç‰ˆæœ¬: {comparison['timestamps']['optimized']}")
            
            # èŒƒå›´æ¯”è¾ƒ
            range_comp = comparison['range_comparison']
            print(f"\nèŒƒå›´æ¯”è¾ƒ:")
            print(f"  m/zèŒƒå›´åŒ¹é…: {range_comp['mz_range_match']} "
                  f"({range_comp['mz_range_original']} vs {range_comp['mz_range_optimized']})")
            print(f"  IMèŒƒå›´åŒ¹é…: {range_comp['im_range_match']} "
                  f"({range_comp['im_range_original']} vs {range_comp['im_range_optimized']})")
            
            # MS1æ¯”è¾ƒ
            ms1_comp = comparison['ms1_comparison']
            print(f"\nMS1 æ•°æ®æ¯”è¾ƒ:")
            print(f"  æ•°æ®ç‚¹æ•° - åŸå§‹: {ms1_comp['data_points_original']}, "
                  f"ä¼˜åŒ–: {ms1_comp['data_points_optimized']}, "
                  f"å·®å¼‚: {ms1_comp['data_points_diff']}")
            
            if 'matched_points' in ms1_comp:
                print(f"  åŒ¹é…çš„æ•°æ®ç‚¹: {ms1_comp['matched_points']}")
                print(f"  åŒ¹é…ç‡: {ms1_comp['match_rate']:.3f}")
                print(f"  ä»…åœ¨åŸå§‹ç‰ˆæœ¬: {ms1_comp['unmatched_in_original']}")
                print(f"  ä»…åœ¨ä¼˜åŒ–ç‰ˆæœ¬: {ms1_comp['unmatched_in_optimized']}")
                print(f"  å¼ºåº¦å·®å¼‚ç‚¹æ•°: {ms1_comp['intensity_differences_count']}")
                if ms1_comp['max_intensity_diff'] > 0:
                    print(f"  æœ€å¤§å¼ºåº¦å·®å¼‚: {ms1_comp['max_intensity_diff']:.2e}")
                    print(f"  å¹³å‡å¼ºåº¦å·®å¼‚: {ms1_comp['mean_intensity_diff']:.2e}")
                else:
                    print(f"  å¼ºåº¦å·®å¼‚: æ— ")
                print(f"  è´¨é‡è¯„ä¼°: {ms1_comp['quality_assessment']}")
            
            # MS2æ¯”è¾ƒ
            ms2_comp = comparison['ms2_comparison']
            print(f"\nMS2 æ•°æ®æ¯”è¾ƒ:")
            print(f"  ç¢ç‰‡æ•° - åŸå§‹: {ms2_comp['num_fragments_original']}, "
                  f"ä¼˜åŒ–: {ms2_comp['num_fragments_optimized']}, "
                  f"å·®å¼‚: {ms2_comp['fragments_diff']}")
            print(f"  æ•°æ®ç‚¹æ•° - åŸå§‹: {ms2_comp['data_points_original']}, "
                  f"ä¼˜åŒ–: {ms2_comp['data_points_optimized']}, "
                  f"å·®å¼‚: {ms2_comp['data_points_diff']}")
            
            if 'matched_points' in ms2_comp:
                print(f"  åŒ¹é…çš„æ•°æ®ç‚¹: {ms2_comp['matched_points']}")
                print(f"  åŒ¹é…ç‡: {ms2_comp['match_rate']:.3f}")
                print(f"  ä»…åœ¨åŸå§‹ç‰ˆæœ¬: {ms2_comp['unmatched_in_original']}")
                print(f"  ä»…åœ¨ä¼˜åŒ–ç‰ˆæœ¬: {ms2_comp['unmatched_in_optimized']}")
                print(f"  å¼ºåº¦å·®å¼‚ç‚¹æ•°: {ms2_comp['intensity_differences_count']}")
                if ms2_comp['max_intensity_diff'] > 0:
                    print(f"  æœ€å¤§å¼ºåº¦å·®å¼‚: {ms2_comp['max_intensity_diff']:.2e}")
                    print(f"  å¹³å‡å¼ºåº¦å·®å¼‚: {ms2_comp['mean_intensity_diff']:.2e}")
                else:
                    print(f"  å¼ºåº¦å·®å¼‚: æ— ")
                print(f"  è´¨é‡è¯„ä¼°: {ms2_comp['quality_assessment']}")
            
            print("\n" + "="*70 + "\n")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        print("æ­£åœ¨ä¿å­˜è¯¦ç»†æŠ¥å‘Š...")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = os.path.join(self.result_dir, f"tolerance_comparison_report_{timestamp}.json")
        with open(report_file, 'w') as f:
            json.dump(all_comparisons, f, indent=2)
        
        print(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        # ç”Ÿæˆæ±‡æ€»
        self._generate_summary(all_comparisons)
    
    def _generate_summary(self, comparisons: List[Dict]):
        """ç”Ÿæˆæ±‡æ€»ä¿¡æ¯"""
        print("\n=== æ±‡æ€»è¯„ä¼° ===")
        
        all_excellent = True
        all_good = True
        
        for comp in comparisons:
            range_comp = comp['range_comparison']
            ms1_comp = comp['ms1_comparison']
            ms2_comp = comp['ms2_comparison']
            
            # æ£€æŸ¥èŒƒå›´åŒ¹é…
            if not (range_comp['mz_range_match'] and range_comp['im_range_match']):
                all_excellent = False
                all_good = False
                print(f"âš ï¸  {comp['precursor_id']}: èŒƒå›´ä¸åŒ¹é…")
                continue
            
            # æ£€æŸ¥æ•°æ®è´¨é‡
            ms1_quality = ms1_comp.get('quality_assessment', 'æ— æ•°æ®')
            ms2_quality = ms2_comp.get('quality_assessment', 'æ— æ•°æ®')
            
            if ms1_quality != 'ä¼˜ç§€' or ms2_quality != 'ä¼˜ç§€':
                all_excellent = False
            
            if ms1_quality in ['å·®'] or ms2_quality in ['å·®']:
                all_good = False
            
            print(f"ğŸ“Š {comp['precursor_id']}: MS1={ms1_quality}, MS2={ms2_quality}")
        
        print(f"\næœ€ç»ˆè¯„ä¼°:")
        if all_excellent:
            print("ğŸ‰ æ‰€æœ‰å‰ä½“çš„åˆ‡ç‰‡ç»“æœåœ¨å®¹å·®èŒƒå›´å†…å®Œå…¨ä¸€è‡´ï¼Œä¼˜åŒ–ç‰ˆæœ¬è´¨é‡ä¼˜ç§€ï¼")
        elif all_good:
            print("âœ… æ‰€æœ‰å‰ä½“çš„åˆ‡ç‰‡ç»“æœåœ¨å®¹å·®èŒƒå›´å†…åŸºæœ¬ä¸€è‡´ï¼Œä¼˜åŒ–ç‰ˆæœ¬è´¨é‡è‰¯å¥½ï¼")
        else:
            print("âš ï¸  éƒ¨åˆ†å‰ä½“çš„åˆ‡ç‰‡ç»“æœå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥")


if __name__ == "__main__":
    result_dir = "/Users/augustsirius/Desktop/DIABERT_test_code_lib/20250714/timstof-slice-optimize/MS1MS2åˆ‡ç‰‡ç»“æœå¯¹æ¯”"
    comparator = ToleranceResultComparator(result_dir)
    comparator.generate_report()